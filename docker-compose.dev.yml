# Valerie Supplier Chatbot - Docker Compose (Development)
# Usage: docker-compose -f docker-compose.dev.yml up
#
# LLM Providers:
#   - Default: Ollama (free, local)
#   - Set VALERIE_USE_PAID_LLM=true for Anthropic

version: '3.8'

services:
  # ==========================================================================
  # API Service (Development with hot reload)
  # ==========================================================================
  api:
    build:
      context: .
      dockerfile: Dockerfile.dev
    container_name: valerie-api-dev
    ports:
      - "8000:8000"
    environment:
      # Environment
      - VALERIE_ENV=development
      # LLM Configuration
      - VALERIE_USE_PAID_LLM=${VALERIE_USE_PAID_LLM:-false}
      - VALERIE_LLM_PROVIDER=${VALERIE_LLM_PROVIDER:-ollama}
      - VALERIE_ANTHROPIC_API_KEY=${VALERIE_ANTHROPIC_API_KEY:-}
      - VALERIE_GROQ_API_KEY=${VALERIE_GROQ_API_KEY:-}
      - VALERIE_OLLAMA_BASE_URL=http://ollama:11434
      # Session Storage (Redis)
      - VALERIE_SESSION_STORE=redis
      - VALERIE_SESSION_REDIS_URL=redis://redis:6379
      - VALERIE_SESSION_TTL=3600
      # Services
      - VALERIE_ORACLE_BASE_URL=http://oracle-mock:3000
      # Observability - LangSmith (dev)
      - LANGCHAIN_TRACING_V2=${LANGCHAIN_TRACING_V2:-true}
      - LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY:-}
      - LANGCHAIN_PROJECT=${LANGCHAIN_PROJECT:-valerie-chatbot-dev}
      # Logging
      - LOG_LEVEL=DEBUG
      - PYTHONPATH=/app/src
    volumes:
      - ./src:/app/src:ro
      - ./demo:/app/demo:ro
      - ./config:/app/config:ro
    depends_on:
      - redis
      - ollama
    command: ["uvicorn", "valerie.api.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
    networks:
      - valerie-dev-network

  # ==========================================================================
  # Redis
  # ==========================================================================
  redis:
    image: redis:7-alpine
    container_name: valerie-redis-dev
    ports:
      - "6379:6379"
    networks:
      - valerie-dev-network

  # ==========================================================================
  # Ollama - Local LLM (Free)
  # ==========================================================================
  ollama:
    image: ollama/ollama:latest
    container_name: valerie-ollama-dev
    ports:
      - "11434:11434"
    volumes:
      - ollama-dev-data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    entrypoint: ["/bin/sh", "-c", "ollama serve & sleep 5 && ollama pull llama3.2 && wait"]
    networks:
      - valerie-dev-network

  # ==========================================================================
  # Oracle Fusion Mock Server
  # ==========================================================================
  oracle-mock:
    image: node:20-alpine
    container_name: valerie-oracle-mock-dev
    working_dir: /app
    ports:
      - "3000:3000"
    volumes:
      - ../oracle-fusion-mock-server:/app:ro
    command: ["npm", "start"]
    networks:
      - valerie-dev-network

  # ==========================================================================
  # Demo UI (Streamlit with hot reload)
  # ==========================================================================
  demo:
    image: python:3.11-slim
    container_name: valerie-demo-dev
    working_dir: /app
    ports:
      - "8501:8501"
    environment:
      - API_URL=http://api:8000
      - VALERIE_LLM_PROVIDER=${VALERIE_LLM_PROVIDER:-ollama}
      - VALERIE_OLLAMA_BASE_URL=http://ollama:11434
    volumes:
      - ./demo:/app/demo:ro
      - ./src:/app/src:ro
      - ./config:/app/config:ro
    command: ["sh", "-c", "pip install streamlit && cd demo && streamlit run app.py --server.address 0.0.0.0"]
    depends_on:
      - api
    networks:
      - valerie-dev-network

# ==========================================================================
# Networks
# ==========================================================================
networks:
  valerie-dev-network:
    driver: bridge

# ==========================================================================
# Volumes
# ==========================================================================
volumes:
  ollama-dev-data:
