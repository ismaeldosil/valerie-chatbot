# Valerie Supplier Chatbot - Docker Compose (Production)
# Usage: docker-compose up -d
#
# LLM Providers:
#   - Default: Ollama (free, local) - set VALERIE_USE_PAID_LLM=false
#   - Paid: Anthropic - set VALERIE_USE_PAID_LLM=true and VALERIE_ANTHROPIC_API_KEY
#   - Free Cloud: Groq - set VALERIE_LLM_PROVIDER=groq and VALERIE_GROQ_API_KEY

version: '3.8'

services:
  # ==========================================================================
  # API Service
  # ==========================================================================
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: valerie-api
    ports:
      - "8000:8000"
    environment:
      # Environment
      - VALERIE_ENV=${VALERIE_ENV:-development}
      # LLM Configuration
      - VALERIE_USE_PAID_LLM=${VALERIE_USE_PAID_LLM:-false}
      - VALERIE_LLM_PROVIDER=${VALERIE_LLM_PROVIDER:-ollama}
      - VALERIE_ANTHROPIC_API_KEY=${VALERIE_ANTHROPIC_API_KEY:-}
      - VALERIE_GROQ_API_KEY=${VALERIE_GROQ_API_KEY:-}
      - VALERIE_OLLAMA_BASE_URL=http://ollama:11434
      # Session Storage (Redis)
      - VALERIE_SESSION_STORE=redis
      - VALERIE_SESSION_REDIS_URL=redis://redis:6379
      - VALERIE_SESSION_TTL=${VALERIE_SESSION_TTL:-3600}
      # Services
      - VALERIE_ORACLE_BASE_URL=http://oracle-mock:3000
      # Observability - LangSmith (dev)
      - LANGCHAIN_TRACING_V2=${LANGCHAIN_TRACING_V2:-false}
      - LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY:-}
      - LANGCHAIN_PROJECT=${LANGCHAIN_PROJECT:-valerie-chatbot}
      # Observability - Langfuse (prod)
      - LANGFUSE_PUBLIC_KEY=${LANGFUSE_PUBLIC_KEY:-}
      - LANGFUSE_SECRET_KEY=${LANGFUSE_SECRET_KEY:-}
      - LANGFUSE_HOST=${LANGFUSE_HOST:-}
      # Logging
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    depends_on:
      redis:
        condition: service_healthy
      ollama:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - valerie-network

  # ==========================================================================
  # Redis - Session Storage
  # ==========================================================================
  redis:
    image: redis:7-alpine
    container_name: valerie-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped
    networks:
      - valerie-network

  # ==========================================================================
  # Ollama - Local LLM (Free)
  # ==========================================================================
  ollama:
    image: ollama/ollama:latest
    container_name: valerie-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    # Pull the default model on startup
    entrypoint: ["/bin/sh", "-c", "ollama serve & sleep 5 && ollama pull llama3.2 && wait"]
    restart: unless-stopped
    networks:
      - valerie-network

  # ==========================================================================
  # Oracle Fusion Mock Server
  # ==========================================================================
  oracle-mock:
    build:
      context: ../oracle-fusion-mock-server
      dockerfile: Dockerfile
    container_name: valerie-oracle-mock
    ports:
      - "3000:3000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - valerie-network

  # ==========================================================================
  # Demo UI (Streamlit)
  # ==========================================================================
  demo:
    build:
      context: .
      dockerfile: Dockerfile.demo
    container_name: valerie-demo
    ports:
      - "8501:8501"
    environment:
      - API_URL=http://api:8000
    depends_on:
      - api
    restart: unless-stopped
    networks:
      - valerie-network

# ==========================================================================
# Networks
# ==========================================================================
networks:
  valerie-network:
    driver: bridge

# ==========================================================================
# Volumes
# ==========================================================================
volumes:
  redis-data:
  ollama-data:
